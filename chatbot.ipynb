{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "def first_data(): \n",
    "    num_class = 5\n",
    "    questions = []\n",
    "    classes = []\n",
    "    with open(\"./content.json\", encoding='utf-8') as f: \n",
    "        # load json file\n",
    "        data = json.load(f)\n",
    "        for type_class in range(num_class): \n",
    "            # get the question data\n",
    "            questions.append(data['intents'][type_class]['input'])\n",
    "            # iterate for label class\n",
    "            for i in range(len(data['intents'][type_class]['input'])): \n",
    "                # get the class data\n",
    "                classes.append(data['intents'][type_class]['tag']) \n",
    "    # return all question and classes\n",
    "    return questions, classes \n",
    "\n",
    "def final_data(questionsm, tags):\n",
    "    final_questions  = []\n",
    "    for row in range(len(questionsm)):\n",
    "        for column in range(len(questionsm[row])): \n",
    "            final_questions.append(questionsm[row][column])\n",
    "    #  define dataframe\n",
    "    df = pd.DataFrame()\n",
    "    # change the previou questions to finalq questions value \n",
    "    df['question'] = final_questions\n",
    "    #  change the previou tags to final tag value \n",
    "    df['tag'] = tags\n",
    "    # return final dataframe\n",
    "    return  df\n",
    "\n",
    "\n",
    "def encode_label(df: pd.DataFrame, tags: pd.Series): \n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.unique(tags))\n",
    "    df['tag'] = le.fit_transform(df['tag'])\n",
    "    return df, le.classes_\n",
    "\n",
    "def get_train_test_data(df: pd.DataFrame): \n",
    "    # drp the tag colunns\n",
    "    feature = np.array(df.drop('tag', axis =1))\n",
    "    target = np.array(df['tag'])\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(feature, target, random_state = 42, test_size = 0.1)\n",
    "    return  X_train, X_test, y_train, y_test\n",
    "\n",
    "def text_preprocesing(text): \n",
    "    #  define stemmer from sastrawi \n",
    "    factory = StemmerFactory()\n",
    "    # stemmer \n",
    "    stemmer = factory.create_stemmer()\n",
    "    for row in range(len(text)): \n",
    "        for column in range(len(text[row])):\n",
    "            text[row][column] = text[row][column].lower()\n",
    "            # delete alfanumeric\n",
    "            text[row][column] = re.sub(r'\\W', ' ', text[row][column])\n",
    "            # delete number\n",
    "            text[row][column] = re.sub(r'\\d+', '', text[row][column])\n",
    "            # delete excessive whitespace\n",
    "            text[row][column] = re.sub(r'\\s+', ' ', text[row][column])\n",
    "            text[row][column] = stemmer.stem(text[row][column])\n",
    "\n",
    "    return text        \n",
    "        \n",
    "\n",
    "def create_model_and_train(x_train, y_train, x_test, y_test):\n",
    "    # trying tokenize \n",
    "    x_train_list = x_train.tolist()\n",
    "    x_test_list = x_test.tolist()\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000, oov_token= \"<OOV>\")\n",
    "    tokenizer.fit_on_texts(x_train_list)\n",
    "\n",
    "    x_train_sequence = tokenizer.texts_to_sequences(x_train_list)\n",
    "    x_train_padded = pad_sequences(x_train_sequence)\n",
    "\n",
    "    x_test_sequence = tokenizer.texts_to_sequences(x_test_list)\n",
    "    x_test_padded = pad_sequences(x_test_sequence)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(None, ))\n",
    "    x = tf.keras.layers.Embedding(1000, 2)(inputs)\n",
    "    x = tf.keras.layers.LSTM(units = 200)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    predictions = tf.keras.layers.Dense(5, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train_padded, y_train,epochs = 200 , validation_data = (x_test_padded, y_test))\n",
    "    return model, history\n",
    "\n",
    "# def predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, classes = first_data()\n",
    "final =  final_data(questions,  classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hei</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assalamualaikum</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apa kabar</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wassup</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selamat datang</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          question       tag\n",
       "0              Hai  greeting\n",
       "1             Halo  greeting\n",
       "2              Hei  greeting\n",
       "3  Assalamualaikum  greeting\n",
       "4               Hi  greeting\n",
       "5        Apa kabar  greeting\n",
       "6               Yo  greeting\n",
       "7           Wassup  greeting\n",
       "8              Hey  greeting\n",
       "9   Selamat datang  greeting"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hei</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assalamualaikum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apa kabar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wassup</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selamat datang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Selamat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Selamat datang kembali</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Selamat berjumpa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Selamat bergabung</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pagi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Siang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sore</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Malam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Salam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Salam sejahtera</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question  tag\n",
       "0                      Hai    2\n",
       "1                     Halo    2\n",
       "2                      Hei    2\n",
       "3          Assalamualaikum    2\n",
       "4                       Hi    2\n",
       "5                Apa kabar    2\n",
       "6                       Yo    2\n",
       "7                   Wassup    2\n",
       "8                      Hey    2\n",
       "9           Selamat datang    2\n",
       "10                 Selamat    2\n",
       "11  Selamat datang kembali    2\n",
       "12        Selamat berjumpa    2\n",
       "13       Selamat bergabung    2\n",
       "14                    Pagi    2\n",
       "15                   Siang    2\n",
       "16                    Sore    2\n",
       "17                   Malam    2\n",
       "18                   Salam    2\n",
       "19         Salam sejahtera    2"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final, class_encode = encode_label(final, final['tag'])\n",
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general', 'goodbye', 'greeting', 'izin', 'sakit'], dtype=object)"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_preprocesing(X_train)\n",
    "X_test = text_preprocesing(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.1979 - loss: 1.6100 - val_accuracy: 0.1600 - val_loss: 1.6099\n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1603 - loss: 1.6100 - val_accuracy: 0.2400 - val_loss: 1.6092\n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2417 - loss: 1.6091 - val_accuracy: 0.2400 - val_loss: 1.6099\n",
      "Epoch 4/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2372 - loss: 1.6092 - val_accuracy: 0.1600 - val_loss: 1.6101\n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2269 - loss: 1.6095 - val_accuracy: 0.2400 - val_loss: 1.6091\n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2906 - loss: 1.6080 - val_accuracy: 0.2400 - val_loss: 1.6088\n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2898 - loss: 1.6065 - val_accuracy: 0.1600 - val_loss: 1.6089\n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2302 - loss: 1.6049 - val_accuracy: 0.1600 - val_loss: 1.6096\n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3016 - loss: 1.6018 - val_accuracy: 0.2000 - val_loss: 1.6090\n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3586 - loss: 1.5937 - val_accuracy: 0.2000 - val_loss: 1.6073\n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3276 - loss: 1.5845 - val_accuracy: 0.2400 - val_loss: 1.6036\n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3957 - loss: 1.5639 - val_accuracy: 0.2400 - val_loss: 1.5962\n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4112 - loss: 1.5382 - val_accuracy: 0.2400 - val_loss: 1.5903\n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4359 - loss: 1.4878 - val_accuracy: 0.2400 - val_loss: 1.5864\n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3944 - loss: 1.4356 - val_accuracy: 0.2400 - val_loss: 1.5757\n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4601 - loss: 1.3327 - val_accuracy: 0.2400 - val_loss: 1.5643\n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4661 - loss: 1.2258 - val_accuracy: 0.2400 - val_loss: 1.5539\n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4837 - loss: 1.1396 - val_accuracy: 0.2400 - val_loss: 1.5541\n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4647 - loss: 1.0438 - val_accuracy: 0.2400 - val_loss: 1.5775\n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5309 - loss: 0.9757 - val_accuracy: 0.2400 - val_loss: 1.6064\n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6068 - loss: 0.9272 - val_accuracy: 0.2000 - val_loss: 1.5871\n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6037 - loss: 0.8847 - val_accuracy: 0.2400 - val_loss: 1.6296\n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6230 - loss: 0.8427 - val_accuracy: 0.2800 - val_loss: 1.6694\n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5623 - loss: 0.7936 - val_accuracy: 0.2400 - val_loss: 1.6760\n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6049 - loss: 0.7716 - val_accuracy: 0.2400 - val_loss: 1.7321\n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6215 - loss: 0.7236 - val_accuracy: 0.2400 - val_loss: 1.8207\n",
      "Epoch 27/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7063 - loss: 0.6988 - val_accuracy: 0.1600 - val_loss: 1.9179\n",
      "Epoch 28/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6770 - loss: 0.6698 - val_accuracy: 0.2000 - val_loss: 1.9937\n",
      "Epoch 29/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7823 - loss: 0.6401 - val_accuracy: 0.2400 - val_loss: 2.0783\n",
      "Epoch 30/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.6060 - val_accuracy: 0.2400 - val_loss: 2.2042\n",
      "Epoch 31/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7378 - loss: 0.5704 - val_accuracy: 0.2000 - val_loss: 2.3205\n",
      "Epoch 32/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7744 - loss: 0.5476 - val_accuracy: 0.2000 - val_loss: 2.4739\n",
      "Epoch 33/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8025 - loss: 0.5266 - val_accuracy: 0.2400 - val_loss: 2.6349\n",
      "Epoch 34/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.5119 - val_accuracy: 0.2400 - val_loss: 2.7483\n",
      "Epoch 35/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7992 - loss: 0.4819 - val_accuracy: 0.2400 - val_loss: 2.8664\n",
      "Epoch 36/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7781 - loss: 0.4733 - val_accuracy: 0.2400 - val_loss: 2.9227\n",
      "Epoch 37/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8877 - loss: 0.4257 - val_accuracy: 0.2400 - val_loss: 2.9290\n",
      "Epoch 38/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8670 - loss: 0.4113 - val_accuracy: 0.2400 - val_loss: 3.0567\n",
      "Epoch 39/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.3644 - val_accuracy: 0.2400 - val_loss: 3.1154\n",
      "Epoch 40/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.3618 - val_accuracy: 0.2400 - val_loss: 3.1346\n",
      "Epoch 41/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9538 - loss: 0.3132 - val_accuracy: 0.2400 - val_loss: 3.1895\n",
      "Epoch 42/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.2991 - val_accuracy: 0.2400 - val_loss: 3.2797\n",
      "Epoch 43/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9620 - loss: 0.3026 - val_accuracy: 0.2400 - val_loss: 3.3840\n",
      "Epoch 44/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9325 - loss: 0.2799 - val_accuracy: 0.2400 - val_loss: 3.4838\n",
      "Epoch 45/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2666 - val_accuracy: 0.3200 - val_loss: 3.5747\n",
      "Epoch 46/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.2578 - val_accuracy: 0.3200 - val_loss: 3.6388\n",
      "Epoch 47/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.2286 - val_accuracy: 0.3200 - val_loss: 3.7192\n",
      "Epoch 48/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.2176 - val_accuracy: 0.3200 - val_loss: 3.7954\n",
      "Epoch 49/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.2047 - val_accuracy: 0.3200 - val_loss: 3.8524\n",
      "Epoch 50/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9681 - loss: 0.1809 - val_accuracy: 0.3200 - val_loss: 3.9043\n",
      "Epoch 51/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1892 - val_accuracy: 0.3200 - val_loss: 4.0049\n",
      "Epoch 52/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.1823 - val_accuracy: 0.3200 - val_loss: 4.0351\n",
      "Epoch 53/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9606 - loss: 0.1690 - val_accuracy: 0.3200 - val_loss: 4.1109\n",
      "Epoch 54/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.1304 - val_accuracy: 0.3200 - val_loss: 4.2118\n",
      "Epoch 55/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9470 - loss: 0.1568 - val_accuracy: 0.3200 - val_loss: 4.2078\n",
      "Epoch 56/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.1434 - val_accuracy: 0.3200 - val_loss: 4.2477\n",
      "Epoch 57/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9381 - loss: 0.1362 - val_accuracy: 0.3200 - val_loss: 4.3385\n",
      "Epoch 58/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9499 - loss: 0.1258 - val_accuracy: 0.3200 - val_loss: 4.3292\n",
      "Epoch 59/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.1233 - val_accuracy: 0.3200 - val_loss: 4.2789\n",
      "Epoch 60/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9800 - loss: 0.0939 - val_accuracy: 0.2400 - val_loss: 4.1767\n",
      "Epoch 61/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.1070 - val_accuracy: 0.3200 - val_loss: 4.2993\n",
      "Epoch 62/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0737 - val_accuracy: 0.2400 - val_loss: 4.2594\n",
      "Epoch 63/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 0.2400 - val_loss: 4.2391\n",
      "Epoch 64/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0406 - val_accuracy: 0.2400 - val_loss: 4.3033\n",
      "Epoch 65/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0399 - val_accuracy: 0.2400 - val_loss: 4.3757\n",
      "Epoch 66/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.2400 - val_loss: 4.4309\n",
      "Epoch 67/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0337 - val_accuracy: 0.2400 - val_loss: 4.4912\n",
      "Epoch 68/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 0.2400 - val_loss: 4.5378\n",
      "Epoch 69/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.2400 - val_loss: 4.5866\n",
      "Epoch 70/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.2400 - val_loss: 4.6441\n",
      "Epoch 71/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.2400 - val_loss: 4.7033\n",
      "Epoch 72/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.2400 - val_loss: 4.7471\n",
      "Epoch 73/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.2400 - val_loss: 4.7851\n",
      "Epoch 74/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.2400 - val_loss: 4.8107\n",
      "Epoch 75/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.2400 - val_loss: 4.8596\n",
      "Epoch 76/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.2400 - val_loss: 4.9128\n",
      "Epoch 77/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.2400 - val_loss: 4.9843\n",
      "Epoch 78/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.2400 - val_loss: 5.0326\n",
      "Epoch 79/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.2400 - val_loss: 5.0712\n",
      "Epoch 80/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.2400 - val_loss: 5.1052\n",
      "Epoch 81/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.2400 - val_loss: 5.1369\n",
      "Epoch 82/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.2400 - val_loss: 5.1814\n",
      "Epoch 83/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.2400 - val_loss: 5.2483\n",
      "Epoch 84/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.2400 - val_loss: 5.2884\n",
      "Epoch 85/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.2400 - val_loss: 5.3208\n",
      "Epoch 86/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.2400 - val_loss: 5.3467\n",
      "Epoch 87/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.2400 - val_loss: 5.3706\n",
      "Epoch 88/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.2400 - val_loss: 5.3860\n",
      "Epoch 89/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.2400 - val_loss: 5.4451\n",
      "Epoch 90/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.2400 - val_loss: 5.4795\n",
      "Epoch 91/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.2400 - val_loss: 5.5140\n",
      "Epoch 92/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.2400 - val_loss: 5.5624\n",
      "Epoch 93/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.2400 - val_loss: 5.5996\n",
      "Epoch 94/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.2400 - val_loss: 5.6275\n",
      "Epoch 95/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.2400 - val_loss: 5.6494\n",
      "Epoch 96/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.2400 - val_loss: 5.6715\n",
      "Epoch 97/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.2400 - val_loss: 5.7189\n",
      "Epoch 98/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.2400 - val_loss: 5.7398\n",
      "Epoch 99/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.2400 - val_loss: 5.7660\n",
      "Epoch 100/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.2400 - val_loss: 5.7937\n",
      "Epoch 101/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.2400 - val_loss: 5.8213\n",
      "Epoch 102/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.2400 - val_loss: 5.8754\n",
      "Epoch 103/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.2400 - val_loss: 5.8987\n",
      "Epoch 104/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.2400 - val_loss: 5.9425\n",
      "Epoch 105/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.2400 - val_loss: 5.9701\n",
      "Epoch 106/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.2400 - val_loss: 5.9900\n",
      "Epoch 107/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.2400 - val_loss: 6.0048\n",
      "Epoch 108/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.2400 - val_loss: 6.0369\n",
      "Epoch 109/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.2400 - val_loss: 6.0649\n",
      "Epoch 110/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.2400 - val_loss: 6.0834\n",
      "Epoch 111/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.2400 - val_loss: 6.0980\n",
      "Epoch 112/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.2400 - val_loss: 6.1170\n",
      "Epoch 113/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.2400 - val_loss: 6.1291\n",
      "Epoch 114/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.2400 - val_loss: 6.1456\n",
      "Epoch 115/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.2400 - val_loss: 6.1686\n",
      "Epoch 116/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.2400 - val_loss: 6.2028\n",
      "Epoch 117/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.2400 - val_loss: 6.2331\n",
      "Epoch 118/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.2400 - val_loss: 6.2842\n",
      "Epoch 119/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.2400 - val_loss: 6.3141\n",
      "Epoch 120/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.2400 - val_loss: 6.3345\n",
      "Epoch 121/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.2400 - val_loss: 6.3514\n",
      "Epoch 122/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.2400 - val_loss: 6.3634\n",
      "Epoch 123/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.2400 - val_loss: 6.3778\n",
      "Epoch 124/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.2400 - val_loss: 6.3967\n",
      "Epoch 125/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.2400 - val_loss: 6.4148\n",
      "Epoch 126/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.2400 - val_loss: 6.4253\n",
      "Epoch 127/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.2400 - val_loss: 6.4436\n",
      "Epoch 128/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.2400 - val_loss: 6.4658\n",
      "Epoch 129/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.2400 - val_loss: 6.5104\n",
      "Epoch 130/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.2400 - val_loss: 6.5345\n",
      "Epoch 131/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.2400 - val_loss: 6.5567\n",
      "Epoch 132/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.5816\n",
      "Epoch 133/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.6207\n",
      "Epoch 134/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.6495\n",
      "Epoch 135/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.6858\n",
      "Epoch 136/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.7009\n",
      "Epoch 137/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.2400 - val_loss: 6.7122\n",
      "Epoch 138/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.2400 - val_loss: 6.7240\n",
      "Epoch 139/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2400 - val_loss: 6.7564\n",
      "Epoch 140/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2400 - val_loss: 6.7728\n",
      "Epoch 141/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.2400 - val_loss: 6.7830\n",
      "Epoch 142/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.2400 - val_loss: 6.8075\n",
      "Epoch 143/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2400 - val_loss: 6.8247\n",
      "Epoch 144/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2400 - val_loss: 6.8343\n",
      "Epoch 145/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2400 - val_loss: 6.8438\n",
      "Epoch 146/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2400 - val_loss: 6.8518\n",
      "Epoch 147/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2400 - val_loss: 6.8635\n",
      "Epoch 148/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2400 - val_loss: 6.8766\n",
      "Epoch 149/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2400 - val_loss: 6.9043\n",
      "Epoch 150/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2400 - val_loss: 6.9195\n",
      "Epoch 151/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2400 - val_loss: 6.9310\n",
      "Epoch 152/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2400 - val_loss: 6.9456\n",
      "Epoch 153/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2400 - val_loss: 6.9730\n",
      "Epoch 154/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2400 - val_loss: 6.9925\n",
      "Epoch 155/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2400 - val_loss: 7.0017\n",
      "Epoch 156/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.2400 - val_loss: 7.0104\n",
      "Epoch 157/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.2400 - val_loss: 7.0224\n",
      "Epoch 158/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.0324\n",
      "Epoch 159/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.2400 - val_loss: 7.0414\n",
      "Epoch 160/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2400 - val_loss: 7.0534\n",
      "Epoch 161/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.0687\n",
      "Epoch 162/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2400 - val_loss: 7.0857\n",
      "Epoch 163/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.0982\n",
      "Epoch 164/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.2400 - val_loss: 7.1109\n",
      "Epoch 165/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.1254\n",
      "Epoch 166/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.2400 - val_loss: 7.1411\n",
      "Epoch 167/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 9.7595e-04 - val_accuracy: 0.2400 - val_loss: 7.1512\n",
      "Epoch 168/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.5878e-04 - val_accuracy: 0.2400 - val_loss: 7.1639\n",
      "Epoch 169/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.1742\n",
      "Epoch 170/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.2400 - val_loss: 7.1903\n",
      "Epoch 171/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.1863e-04 - val_accuracy: 0.2400 - val_loss: 7.2211\n",
      "Epoch 172/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.2400 - val_loss: 7.2430\n",
      "Epoch 173/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.7586e-04 - val_accuracy: 0.2400 - val_loss: 7.2717\n",
      "Epoch 174/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.9643e-04 - val_accuracy: 0.2400 - val_loss: 7.2989\n",
      "Epoch 175/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.7395e-04 - val_accuracy: 0.2400 - val_loss: 7.3164\n",
      "Epoch 176/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8531e-04 - val_accuracy: 0.2400 - val_loss: 7.3261\n",
      "Epoch 177/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.1849e-04 - val_accuracy: 0.2400 - val_loss: 7.3290\n",
      "Epoch 178/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7099e-04 - val_accuracy: 0.2400 - val_loss: 7.3404\n",
      "Epoch 179/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.6254e-04 - val_accuracy: 0.2400 - val_loss: 7.3499\n",
      "Epoch 180/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.3577e-04 - val_accuracy: 0.2400 - val_loss: 7.3720\n",
      "Epoch 181/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.5715e-04 - val_accuracy: 0.2400 - val_loss: 7.3887\n",
      "Epoch 182/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.2362e-04 - val_accuracy: 0.2400 - val_loss: 7.4010\n",
      "Epoch 183/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.5045e-04 - val_accuracy: 0.2400 - val_loss: 7.4121\n",
      "Epoch 184/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.7029e-04 - val_accuracy: 0.2400 - val_loss: 7.4228\n",
      "Epoch 185/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.9139e-04 - val_accuracy: 0.2400 - val_loss: 7.4308\n",
      "Epoch 186/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8089e-04 - val_accuracy: 0.2400 - val_loss: 7.4351\n",
      "Epoch 187/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.3955e-04 - val_accuracy: 0.2400 - val_loss: 7.4424\n",
      "Epoch 188/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.9413e-04 - val_accuracy: 0.2400 - val_loss: 7.4524\n",
      "Epoch 189/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.6863e-04 - val_accuracy: 0.2400 - val_loss: 7.4624\n",
      "Epoch 190/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3925e-04 - val_accuracy: 0.2400 - val_loss: 7.4742\n",
      "Epoch 191/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.5701e-04 - val_accuracy: 0.2400 - val_loss: 7.4836\n",
      "Epoch 192/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.8322e-04 - val_accuracy: 0.2400 - val_loss: 7.4919\n",
      "Epoch 193/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.9184e-04 - val_accuracy: 0.2400 - val_loss: 7.5027\n",
      "Epoch 194/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.9792e-04 - val_accuracy: 0.2400 - val_loss: 7.5117\n",
      "Epoch 195/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.2746e-04 - val_accuracy: 0.2400 - val_loss: 7.5270\n",
      "Epoch 196/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.5761e-04 - val_accuracy: 0.2400 - val_loss: 7.5485\n",
      "Epoch 197/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.7303e-04 - val_accuracy: 0.2400 - val_loss: 7.5632\n",
      "Epoch 198/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.1763e-04 - val_accuracy: 0.2400 - val_loss: 7.5757\n",
      "Epoch 199/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.4286e-04 - val_accuracy: 0.2400 - val_loss: 7.5866\n",
      "Epoch 200/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0156e-04 - val_accuracy: 0.2400 - val_loss: 7.5945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Functional name=functional_63, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x22eab45cb90>)"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_and_train(X_train, y_train, X_test, y_test)\n",
    "# create_model_and_train(df=df_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
