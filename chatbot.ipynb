{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "def first_data(): \n",
    "    num_class = 5\n",
    "    questions = []\n",
    "    classes = []\n",
    "    with open(\"./content.json\", encoding='utf-8') as f: \n",
    "        # load json file\n",
    "        data = json.load(f)\n",
    "        for type_class in range(num_class): \n",
    "            # get the question data\n",
    "            questions.append(data['intents'][type_class]['input'])\n",
    "            # iterate for label class\n",
    "            for i in range(len(data['intents'][type_class]['input'])): \n",
    "                # get the class data\n",
    "                classes.append(data['intents'][type_class]['tag']) \n",
    "    # return all question and classes\n",
    "    return questions, classes \n",
    "\n",
    "def final_data(questionsm, tags):\n",
    "    final_questions  = []\n",
    "    for row in range(len(questionsm)):\n",
    "        for column in range(len(questionsm[row])): \n",
    "            final_questions.append(questionsm[row][column])\n",
    "    #  define dataframe\n",
    "    df = pd.DataFrame()\n",
    "    # change the previou questions to finalq questions value \n",
    "    df['question'] = final_questions\n",
    "    #  change the previou tags to final tag value \n",
    "    df['tag'] = tags\n",
    "    # return final dataframe\n",
    "    return  df\n",
    "\n",
    "\n",
    "def encode_label(df: pd.DataFrame, tags: pd.Series): \n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.unique(tags))\n",
    "    df['tag'] = le.fit_transform(df['tag'])\n",
    "    return df, le.classes_\n",
    "\n",
    "def get_train_test_data(df: pd.DataFrame): \n",
    "    # drp the tag colunns\n",
    "    feature = np.array(df.drop('tag', axis =1))\n",
    "    target = np.array(df['tag'])\n",
    "\n",
    "    # the test data will save as xlsx data\n",
    "    X_train, y_train = np.array(feature), np.array(target)\n",
    "    return  X_train, y_train\n",
    "\n",
    "def text_preprocesing(text): \n",
    "    #  define stemmer from sastrawi \n",
    "    factory = StemmerFactory()\n",
    "    # stemmer \n",
    "    stemmer = factory.create_stemmer()\n",
    "    for row in range(len(text)): \n",
    "        for column in range(len(text[row])):\n",
    "            text[row][column] = text[row][column].lower()\n",
    "            # delete alfanumeric\n",
    "            text[row][column] = re.sub(r'\\W', ' ', text[row][column])\n",
    "            # delete number\n",
    "            text[row][column] = re.sub(r'\\d+', '', text[row][column])\n",
    "            # delete excessive whitespace\n",
    "            text[row][column] = re.sub(r'\\s+', ' ', text[row][column])\n",
    "            text[row][column] = stemmer.stem(text[row][column])\n",
    "\n",
    "    return text        \n",
    "        \n",
    "\n",
    "def create_model_and_train(x_train, y_train):\n",
    "    # dofine callbacks\n",
    "    class CustomCallbaks(tf.keras.callbacks.Callback): \n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('accuracy')>0.85):\n",
    "                print(\"\\nTrain was stopped\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    # trying tokenize \n",
    "    x_train_list = x_train.tolist()\n",
    "    # define tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000, oov_token= \"<OOV>\")\n",
    "    tokenizer.fit_on_texts(x_train_list)\n",
    "\n",
    "    x_train_sequence = tokenizer.texts_to_sequences(x_train_list)\n",
    "    x_train_padded = pad_sequences(x_train_sequence)\n",
    "    inputs = tf.keras.Input(shape=(None, ))\n",
    "    x = tf.keras.layers.Embedding(1000, 2)(inputs)\n",
    "    x = tf.keras.layers.LSTM(units = 200)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    predictions = tf.keras.layers.Dense(5, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train_padded, y_train,epochs = 200, callbacks= CustomCallbaks())\n",
    "    return model, history, tokenizer\n",
    "\n",
    "def predict_class(text: str, tokenizer, model): \n",
    "    factory = StemmerFactory()\n",
    "    # stemmer \n",
    "    stemmer = factory.create_stemmer()\n",
    "    text= text.lower()\n",
    "    text= re.sub(r'\\W', ' ', text)\n",
    "            # delete number\n",
    "    text= re.sub(r'\\d+', '', text)\n",
    "            # delete excessive whitespace\n",
    "    text= re.sub(r'\\s+', ' ', text)\n",
    "    final_text= stemmer.stem(text)\n",
    "    # final_text = text_preprocesing(text)\n",
    "    print(final_text)\n",
    "    text_tokeneize = tokenizer.texts_to_sequences([final_text])\n",
    "    text_tokeneize = pad_sequences(text_tokeneize)\n",
    "    pred = model.predict(text_tokeneize)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, classes = first_data()\n",
    "final =  final_data(questions,  classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hei</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assalamualaikum</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apa kabar</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yo</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wassup</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selamat datang</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          question       tag\n",
       "0              Hai  greeting\n",
       "1             Halo  greeting\n",
       "2              Hei  greeting\n",
       "3  Assalamualaikum  greeting\n",
       "4               Hi  greeting\n",
       "5        Apa kabar  greeting\n",
       "6               Yo  greeting\n",
       "7           Wassup  greeting\n",
       "8              Hey  greeting\n",
       "9   Selamat datang  greeting"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hei</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assalamualaikum</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apa kabar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wassup</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Selamat datang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Selamat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Selamat datang kembali</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Selamat berjumpa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Selamat bergabung</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pagi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Siang</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sore</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Malam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Salam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Salam sejahtera</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question  tag\n",
       "0                      Hai    2\n",
       "1                     Halo    2\n",
       "2                      Hei    2\n",
       "3          Assalamualaikum    2\n",
       "4                       Hi    2\n",
       "5                Apa kabar    2\n",
       "6                       Yo    2\n",
       "7                   Wassup    2\n",
       "8                      Hey    2\n",
       "9           Selamat datang    2\n",
       "10                 Selamat    2\n",
       "11  Selamat datang kembali    2\n",
       "12        Selamat berjumpa    2\n",
       "13       Selamat bergabung    2\n",
       "14                    Pagi    2\n",
       "15                   Siang    2\n",
       "16                    Sore    2\n",
       "17                   Malam    2\n",
       "18                   Salam    2\n",
       "19         Salam sejahtera    2"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final, class_encode = encode_label(final, final['tag'])\n",
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general', 'goodbye', 'greeting', 'izin', 'sakit'], dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_train_test_data(df_final)\n",
    "# the x train len is : 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_preprocesing(X_train)\n",
    "# X_test = text_preprocesing(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1698 - loss: 1.6097\n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2282 - loss: 1.6095 \n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2103 - loss: 1.6091 \n",
      "Epoch 4/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2154 - loss: 1.6087 \n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1945 - loss: 1.6082 \n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2474 - loss: 1.6068 \n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2862 - loss: 1.6031 \n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2950 - loss: 1.5986 \n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3120 - loss: 1.5934 \n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3905 - loss: 1.5763 \n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.5508 \n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4473 - loss: 1.5134 \n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5238 - loss: 1.4559 \n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 1.3842 \n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 1.2844 \n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5851 - loss: 1.1971 \n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6644 - loss: 1.0279 \n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.9444 \n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7616 - loss: 0.7885 \n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.6644 \n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8045 - loss: 0.5592 \n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4905 \n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.4156 \n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3705 \n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3357 \n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3130 \n",
      "Epoch 27/200\n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.2736\n",
      "Train was stopped\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3028 \n"
     ]
    }
   ],
   "source": [
    "model, history, tokenizer  = create_model_and_train(X_train, y_train)\n",
    "# create_model_and_train(df=df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saya izin tidak ke kantor\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict_class(\"saya izin tidak ke kantor\", tokenizer, model)\n",
    "# class_encode[np.argmax(pred)]\n",
    "np.argmax(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general', 'goodbye', 'greeting', 'izin', 'sakit'], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_encode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
